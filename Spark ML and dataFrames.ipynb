{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing required packages\n",
    "!pip install pyspark\n",
    "!pip install findspark\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c47523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cecdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark DataFrames basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file using `read_csv` function in pandas\n",
    "mtcars = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/mtcars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7788c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a few records\n",
    "mtcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0faca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the `createDataFrame` function to load the data into a spark dataframe\n",
    "sdf = spark.createDataFrame(mtcars) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be365d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us look at the schema of the loaded spark dataframe\n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e9c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db77324",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.select('mpg').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3286fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.filter(sdf['mpg'] < 18).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d32add",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.withColumn('wtTon', sdf['wt'] * 0.45).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9aaffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_new = sdf.withColumnRenamed(\"vs\", \"versus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.where(sdf['mpg'] < 18).show(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6499dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample DataFrame 1 \n",
    "\n",
    "data = [(\"A101\", \"John\"), (\"A102\", \"Peter\"), (\"A103\", \"Charlie\")] \n",
    "\n",
    "columns = [\"emp_id\", \"emp_name\"] \n",
    "\n",
    "dataframe_1 = spark.createDataFrame(data, columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29becb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample DataFrame 2 \n",
    "\n",
    "data = [(\"A101\", 1000), (\"A102\", 2000), (\"A103\", 3000)]\n",
    "\n",
    "columns = [\"emp_id\", \"salary\"]\n",
    "\n",
    "dataframe_2 = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame, \"combined_df\" by performing an inner join\n",
    "\n",
    "combined_df = dataframe_1.join(dataframe_2, on=\"emp_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sample DataFrame 1\n",
    "\n",
    "data = [(\"A101\", 1000), (\"A102\", 2000), (\"A103\",None)]\n",
    "\n",
    "columns = [\"emp_id\", \"salary\"]\n",
    "\n",
    "dataframe_1 = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing salary value with a specified value \n",
    "\n",
    "filled_df = dataframe_1.fillna({\"salary\": 3000}) \n",
    "filled_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9aa77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.groupby(['cyl'])\\\n",
    ".agg({\"wt\": \"AVG\"})\\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211534f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_counts = sdf.groupby(['cyl'])\\\n",
    ".agg({\"wt\": \"count\"})\\\n",
    ".sort(\"count(wt)\", ascending=False)\\\n",
    ".show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae9062",
   "metadata": {},
   "source": [
    "# Introduction to SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d33eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a spark context class\n",
    "sc = SparkContext()\n",
    "\n",
    "# Creating a spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark DataFrames basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056bd689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file using `read_csv` function in pandas\n",
    "mtcars = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/mtcars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a few records\n",
    "mtcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302c3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars.rename( columns={'Unnamed: 0':'name'}, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f81960",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.createDataFrame(mtcars) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2245118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_new = sdf.withColumnRenamed(\"vs\", \"versus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d952977",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced1f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.createTempView(\"cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the whole table\n",
    "spark.sql(\"SELECT * FROM cars\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Pandas UDF function \n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"float\")\n",
    "def convert_wt(s: pd.Series) -> pd.Series:\n",
    "    # The formula for converting from imperial to metric tons\n",
    "    return s * 0.45\n",
    "\n",
    "spark.udf.register(\"convert_weight\", convert_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae35fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT *, wt AS weight_imperial, convert_weight(wt) as weight_metric FROM cars\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9a258a",
   "metadata": {},
   "source": [
    "# Connecting to spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06359c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark==3.1.2 -q\n",
    "!pip install findspark -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4465382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifies the process of using Apache Spark with Python\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# import SparkSession\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482419ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SparkSession\n",
    "#Here 'Getting Started with Spark' is the application name\n",
    "#Ignore any warnings by SparkSession command\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Getting Started with Spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9aecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0231EN-SkillsNetwork/datasets/mpg.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the spark.read.csv function we load the data into a dataframe.\n",
    "# the header = True mentions that there is a header row in out csv file\n",
    "# the inferSchema = True, tells spark to automatically find out the data types of the columns.\n",
    "\n",
    "# Load mpg dataset\n",
    "mpg_data = spark.read.csv(\"mpg.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99237dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show top 5 rows from the dataset\n",
    "mpg_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60982c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9afe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d8ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
